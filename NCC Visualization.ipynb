{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@Created on Tue November 30 17:22:23 2021\n",
    "@Data Warehouse & Mining Visualization\n",
    "@Author: D. Perry\n",
    "\"\"\"\n",
    "\n",
    "# Aim: Which attributes of the dataset determine the Funding Agency on behalf of the contracts that were awarded?\n",
    "# Approach: For this reason two(2) modules were built a Decison Tree and a Neural Network Classifications.\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# These datasets are useful for getting a handle on a given machine learning algorithm.\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder # This line of codes below can encoding the data set individually.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Import Decision Tree Classifier library.\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "# graphviz provides a simple pure-Python interface for the Graphviz graph-drawing software.\n",
    "\n",
    "\n",
    "from IPython.display import Image, display, SVG\n",
    "# Save the model as png file\n",
    "from keras.utils.vis_utils import plot_model \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import scipy.stats as stats\n",
    "import datetime\n",
    "import time \n",
    "\n",
    "from yellowbrick.features import Rank2D\n",
    "from yellowbrick.features import JointPlotVisualizer\n",
    "\n",
    "import pydotplus\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Standard plotly imports\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "\n",
    "# Using plotly + cufflinks in offline mode\n",
    "import cufflinks\n",
    "cufflinks.go_offline(connected=True)\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# indicates that we want our plots to be shown in our notebook and not in a sesparate v\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os # Read input/output from directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to importing Dataset \n",
    "def import_data_source(): \n",
    "    ncc_consolidated_data = pd.read_csv(\"ncc_consolidated.csv\") \n",
    "\n",
    "    # Printing the dataswet shape \n",
    "    print (\"\\nDATASET LENGHT : \", len(ncc_consolidated_data)) \n",
    "    print (\"\\nDATASET SHAPE : \", ncc_consolidated_data.shape) \n",
    "    \n",
    "    input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "    clear_output()\n",
    "    \n",
    "    # Convert string to date format.\n",
    "    ncc_consolidated_data['Date'] = pd.to_datetime(ncc_consolidated_data['Date'], dayfirst=True).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Convert 'Jamaican Equivalent' float values to string, which is categorial data.\n",
    "    ncc_consolidated_data['Jamaican Equivalent'] = ncc_consolidated_data['Jamaican Equivalent'].astype(float)\n",
    "    ncc_consolidated_data['Jamaican Equivalent'].round(decimals = 2)\n",
    "                \n",
    "\n",
    "    # Settings to display all columns\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    # Display the dataframe head\n",
    "    print (\"\\n\\n---- DATA FRAME DATASET OBSERVATION ----\")\n",
    "    print (\"........................................\\n\\n\", ncc_consolidated_data.head())\n",
    "    \n",
    "    input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "    clear_output()\n",
    "    \n",
    "    print (\"\\n --- DATASET VARIABLE TYPES ---\\n\\n\", ncc_consolidated_data.dtypes) \n",
    "    input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "    clear_output()\n",
    "    \n",
    "    return ncc_consolidated_data\n",
    "\n",
    "# I am only interested in some of the columns.\n",
    "# Funnction drop unnecessary columns.\n",
    "def drop_columns(ncc_consolidated):\n",
    "    data = ncc_consolidated.copy().loc[:, (ncc_consolidated.columns != 'ID') & (ncc_consolidated.columns != 'Currency Unit') \n",
    "    & (ncc_consolidated.columns != 'Contract Description') & (ncc_consolidated.columns != 'Dollar Amount') & (ncc_consolidated.columns != 'Comments') & (ncc_consolidated.columns != 'Additional Comments')  \n",
    "    & (ncc_consolidated.columns != 'Column 13')]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Fill in missing values with the most frequent occurrences.\n",
    "def fill_missing_data(ncc_data_sample):\n",
    "    ncc_data_sample = ncc_data_sample.fillna({\"Procurement Method\": \"SURREY PAVING & AGGREGATE CO. LTD\"})\n",
    "    ncc_data_sample = ncc_data_sample.fillna({\"Government Agency\": \"National Works Agency\"})\n",
    "    ncc_data_sample = ncc_data_sample.fillna({\"Contractor\": \"ST\"})\n",
    "    ncc_data_sample = ncc_data_sample.fillna({\"Fund\": \"GOJ\"})\n",
    "    \n",
    "    return ncc_data_sample\n",
    "\n",
    "# Displays out all result.\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 6091, \"display.max_columns\", 11): \n",
    "        display(df)\n",
    "\n",
    "# Function for encoding the data set.\n",
    "def create_label_encoder_dict(input_df):    \n",
    "    label_encoder_dict = {}\n",
    "    for column in input_df.columns:\n",
    "        # Only create encoder for categorical data types\n",
    "        if not np.issubdtype(input_df[column].dtype, np.number) :\n",
    "            label_encoder_dict[column]= LabelEncoder().fit(input_df[column])\n",
    "            \n",
    "    return label_encoder_dict\n",
    "\n",
    "\n",
    "# Function to show encoding of categorical values.\n",
    "def print_label_endoder(ncc_data_encoded):\n",
    "    \n",
    "    print(\"\\t\\t\\t --- ENCODED VALUES FOR EACH LABEL ---\\n\")\n",
    "    print(\"=\"*85)\n",
    "    for column in ncc_data_encoded:\n",
    "        print(\"*\"*85)\n",
    "        print('Encoder(%s) = %s' % (column, ncc_data_encoded[column].classes_ ))\n",
    "        print(\"\\n\")\n",
    "        print(pd.DataFrame([range(0,len(ncc_data_encoded[column].classes_))], columns=ncc_data_encoded[column].classes_, \n",
    "        index=['[******************* ENCODED VALUES SUMMARY *******************]']  ).T)\n",
    "        \n",
    "        input(\"\\n\\t\\tPress Enter to continue here...\")\n",
    "        clear_output()\n",
    "        \n",
    "    \n",
    "    \n",
    "# Fucntion to transforms dataset into encoded numeric values.\n",
    "def trans_data(ncc_data_model, ncc_data_encoded):\n",
    "    for column in ncc_data_model.columns:\n",
    "        if column in ncc_data_encoded:\n",
    "            ncc_data_model[column] = ncc_data_encoded[column].transform(ncc_data_model[column])\n",
    "\n",
    "    print(\"\\t--- TRANSFORMED DATASET | WITH UNIQUE ENCODED VALUES ---\")\n",
    "    print(\"*\"*70)\n",
    "    print(\"*\"*70)\n",
    "    model_data_frame = pd.DataFrame(ncc_data_model)\n",
    "    print(model_data_frame.head())\n",
    "    \n",
    "    return ncc_data_model\n",
    "\n",
    "\n",
    "def dataColumns(ncc_data_model):\n",
    "     # Separate our data into dependent (Y) and independent(X) variables to build model.\n",
    "    data = ncc_data_model[['Date', 'Government Agency', 'Funding Agency', 'Contractor', 'Procurement Method', \n",
    "                           'Jamaican Equivalent']]\n",
    "    return data\n",
    "\n",
    "\n",
    "def axis(ncc_data_model):\n",
    "     # Separate our data into dependent (Y) and independent(X) variables to build model.\n",
    "    X = ncc_data_model[['Date', 'Government Agency', 'Contractor', 'Procurement Method', 'Jamaican Equivalent']]\n",
    "    Y = ncc_data_model['Funding Agency']\n",
    "    \n",
    "    return x, y\n",
    "    \n",
    "# Function to split the dataset \n",
    "def splitdataset(ncc_data_model): \n",
    "\n",
    "    # Seperating data into features and target variables.\n",
    "    # Separate our data into dependent (Y) and independent(X) variables to build model.\n",
    "    X = ncc_data_model[['Date', 'Government Agency', 'Contractor', 'Procurement Method', 'Jamaican Equivalent']]\n",
    "    Y = ncc_data_model['Funding Agency']\n",
    "    \n",
    "\n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split( \n",
    "    X, Y, test_size = 0.30) # 70% training and 30% test\n",
    "    \n",
    "    return X, Y, X_train, X_test, y_train, y_test \n",
    "\n",
    "\n",
    "#Function to show X and Y data axises. \n",
    "def print_axis(X_data, Y_data):\n",
    "    print(\"SHOW X : \\n\", X_data.head())\n",
    "    print(\"\\nSHOW Y :\\n\", Y_data.head())\n",
    "\n",
    "#Function to validate the percentage spit.     \n",
    "def percentage_spit(X_train):\n",
    "    print(\"DATA MODEL SPLIT : \", X_train.shape)\n",
    "    print(\"CALCULATED FIGURE : \", 6091 * 0.7)\n",
    "    \n",
    "    \n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, y_train): \n",
    "\n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier(criterion='entropy', splitter = 'random', max_depth=3,\n",
    "                  min_samples_leaf = 2, min_samples_split=2) \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    \n",
    "    return clf_entropy \n",
    "\n",
    "\n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, y_train): \n",
    "    \n",
    "    # Decision tree with entropy \n",
    "    clf_gini = DecisionTreeClassifier(criterion='gini', splitter = 'random', max_depth=3, \n",
    "                  min_samples_split=2) \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    \n",
    "    return clf_gini\n",
    "\n",
    "\n",
    "\n",
    "# Function to show the important features in the data model.\n",
    "def sig_features(clf, x_data):\n",
    "    print(pd.DataFrame([ \"%.2f%%\" % perc for perc in (clf.feature_importances_ * 100) ], \n",
    "    index = x_data.columns, columns = ['Feature Significance in Decision Tree']))\n",
    "\n",
    " \n",
    " \n",
    "# Function to visualize Decision Tree Classification.\n",
    "def tree_visualization(ncc_data_encoded, clf_obj, X_data, Y_data):\n",
    "\n",
    "    # Visualize data.\n",
    "    tree_data = tree.export_graphviz(clf_obj,out_file=None, \n",
    "    feature_names=X_data.columns, \n",
    "    class_names=ncc_data_encoded[Y_data.name].classes_,  \n",
    "    filled=True, rounded=True,  proportion=True,\n",
    "    node_ids=True, #impurity=False,\n",
    "    special_characters=True)\n",
    "    \n",
    "    return tree_data\n",
    "    \n",
    "    \n",
    "\n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object, y_test): \n",
    "\n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    y_pred_cnt = (clf_object.predict(X_test) == y_test) \n",
    "    \n",
    "    print(\"Predicted values : \", y_pred) \n",
    "    print(\"\\nPredicted values count : \", y_pred_cnt.value_counts()) \n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Function to calculate accuracy.\n",
    "def cal_accuracy(y_test, y_pred): \n",
    "\n",
    "    score = accuracy_score(y_test,y_pred)*100\n",
    "    \n",
    "    print(\"\\nCONFUSION MATRIX: \\n\", confusion_matrix(y_test, y_pred)) \n",
    "\n",
    "    print(\"\\n\\nACCURACY USING DECISION TREE : \", round(score, 2), \"%\")\n",
    "    \n",
    "    print(\"\\n\\nCLASSIFICATION REPORT : \\n\", classification_report(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "# Function use to plot confusion matrix.   \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    import itertools\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix :\\n\\n\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization :\\n\\n')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Transforms features by scaling each feature to a given range.\n",
    "def create_min_max_scaler_dict(df):\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "    min_max_scaler_dict = {}\n",
    "    for column in df.columns:\n",
    "        # Only create encoder for categorical data types\n",
    "        if np.issubdtype(df[column].dtype, np.number):\n",
    "            min_max_scaler_dict[column]= MinMaxScaler().fit(pd.DataFrame(df[column]))\n",
    "            \n",
    "    return min_max_scaler_dict\n",
    "\n",
    "\n",
    "# Function for pandas dataframe columns scaling.\n",
    "def scalers_dataframe(dataset):\n",
    "\n",
    "    scalers_df =pd.DataFrame([\n",
    "    {\n",
    "        'column':col,\n",
    "        'min':min_max_scalers[col].dataset_min_[0],\n",
    "        'max':min_max_scalers[col].dataset_max_[0],\n",
    "        'range':min_max_scalers[col].dataset_range_[0] \n",
    "    } for col in min_max_scalers])\n",
    "    \n",
    "    scalers_df \n",
    "#-------------------------------------- Function ends. ------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menu display options.\n",
    "\n",
    "def main_option_menu():\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"\\n\\t\\t~~                                                        ~~\")\n",
    "    print(\"\\n\\t\\t~~      DATA WAREHOUSE & DATA MINING VISUALIZATION        ~~\")\n",
    "    print(\"\\n\\t\\t~~                      (DWDM)                            ~~\")\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"\\n\\t\\t~~                                                        ~~\")\n",
    "    print(\"\\n\\t\\t~~          ->0. EXIT                                     ~~\")\n",
    "    print(\"\\n\\t\\t~~          ->1. INITIALIZE DATASET                       ~~\")\n",
    "    print(\"\\n\\t\\t~~                                                        ~~\")\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "   \n",
    "    \n",
    "def sub_menu():\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"\\n\\t\\t~~                                                        ~~\")\n",
    "    print(\"\\n\\t\\t~~      DATA WAREHOUSE & DATA MINING VISUALIZATION        ~~\")\n",
    "    print(\"\\n\\t\\t~~               (BUILD DATA MODEL)                       ~~\")\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"\\n\\t\\t~~                                                        ~~\")\n",
    "    print(\"\\n\\t\\t~~          ->0. RETURN TO MAIN                           ~~\")\n",
    "    print(\"\\n\\t\\t~~          ->1. DECISION TREE CLASSIFICATION             ~~\")\n",
    "    print(\"\\n\\t\\t~~          ->2. NEURAL NETWORK CLASSIFICATION            ~~\")\n",
    "    print(\"\\n\\t\\t~~          ->3. DATASET VISUALIZATIONS                   ~~\")\n",
    "    print(\"\\n\\t\\t~~                                                        ~~\")\n",
    "    print(\"\\n\\t\\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "#----------------------------------------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function main application menu.\n",
    "def app_menu():      \n",
    "    try:\n",
    "        clear_output()\n",
    "        loop = True  # Condition Initialis    \n",
    "        \n",
    "        while loop:  # While loop which will keep going until loop condition is False\n",
    "            main_option_menu()\n",
    "            \n",
    "            print('\\n\\n')\n",
    "            # Accept user input for option here.\n",
    "            choice = str(input(\"\\t\\tEnter your choice [0 & 1]: \"))\n",
    "            clear_output()\n",
    "            \n",
    "           #................................................................................................................#\n",
    "            if choice=='0':  \n",
    "                clear_output()\n",
    "                print (\"\\n\\n\\t\\t[--- APPLICATION CLOSED ---]\")\n",
    "                time.sleep(3)\n",
    "                loop=False # This will make the while loop to end as not value of loop is set to False\n",
    "           #................................................................................................................#\n",
    "            elif choice=='1':  \n",
    "                print (\"\\n\\n[---  INITIALIZE DATASET   ---]\")\n",
    "                # Load and store dataset to variable.\n",
    "                ncc_consolidated = import_data_source()\n",
    "\n",
    "                # Strip leading and trailing space from dataset.\n",
    "                ncc_consolidated['Fund'] = ncc_consolidated['Fund'].str.strip()\n",
    "                ncc_consolidated['Government Agency'] = ncc_consolidated['Government Agency'].str.strip()\n",
    "                ncc_consolidated['Contractor'] = ncc_consolidated['Contractor'].str.strip()\n",
    "                ncc_consolidated['Procurement Method'] = ncc_consolidated['Procurement Method'].str.strip()\n",
    "\n",
    "                # Remove multiple spaces between two strings\n",
    "                ncc_consolidated = ncc_consolidated.replace('\\s+', ' ', regex=True)\n",
    "                ncc_consolidated['Procurement Method'] = ncc_consolidated['Procurement Method'].replace('\\s+', ' ', regex=True)\n",
    "                ncc_consolidated['Procurement Method'] = ncc_consolidated['Procurement Method'].str.replace(\" \",\"\")\n",
    "\n",
    "                # Rename Procurement Method duplicate names data column values.\n",
    "                ncc_consolidated['Procurement Method'].replace(['*', 'DC*','', ' '], 'DC')\n",
    "                ncc_consolidated['Procurement Method'].replace(['*', 'DC*'], 'DC')\n",
    "\n",
    "                # Rename Government Agency duplicate names data column values.\n",
    "                ncc_consolidated.rename(index={'University Hospital of  the West indies': 'University Hospital of the West Indies, Mona'})\n",
    "                ncc_consolidated.rename(index={'University Hospital of the West Indies': 'University Hospital of the West Indies, Mona'})\n",
    "                ncc_consolidated.rename(index={'University Hospital of  the West indies (UHWI)': 'University Hospital of the West Indies, Mona'})\n",
    "\n",
    "                # Rename Government Agency duplicate names data column values.\n",
    "                ncc_consolidated['Government Agency'].replace('University of Technology, Jamaica,  Jamaica', 'University of Technology, Jamaica (UTECH)') \n",
    "                ncc_consolidated['Government Agency'].replace('University of Technology, Jamaica\t', 'University of Technology, Jamaica (UTECH)') \n",
    "                ncc_consolidated['Government Agency'].replace('University of Technology,Jamaica', 'University of Technology, Jamaica (UTECH)') \n",
    "                ncc_consolidated['Government Agency'].replace('University of Technology, Jamaica', 'University of Technology, Jamaica (UTECH)') \n",
    "\n",
    "\n",
    "                # Drop unnecessary columns in dataset.\n",
    "                ncc_data = drop_columns(ncc_consolidated)\n",
    "\n",
    "                ncc_data_sample = ncc_data.copy()\n",
    "\n",
    "                print(\"\\n\")\n",
    "                ncc_data_sample.describe()\n",
    "\n",
    "                ncc_data_sample.dtypes\n",
    "\n",
    "                ncc_data_sample.head(6)\n",
    "\n",
    "                # Look for missing dataset column values.\n",
    "                print (\"--- COUNT MISSING DATA --- \\n\")\n",
    "                print(ncc_data_sample.isnull().sum())\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # This method prints information about the DataFrame.\n",
    "                print (\"\\n[----  DATA SET INFORMATION  ----]\\n\")\n",
    "                ncc_data_sample.info()\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "\n",
    "                # Fill in missing values with the most frequent occurrences.\n",
    "                ncc_clean_data = fill_missing_data(ncc_data_sample)\n",
    "                \n",
    "                print (\" --- VERIFY MISSING DATA FILLED IN --- \\n\")\n",
    "                print(ncc_clean_data.isnull().sum())\n",
    "\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # Returns the column headings to indicate the dataset that is working on.\n",
    "                print (\"\\n\\n[---- DISPLAY DATASET AFTER DROPPING UNECESSARY COLUMNS ----]\")\n",
    "                # display the dataframe head\n",
    "                print (\"[...........................................................]\\n\\n\", ncc_clean_data.head())\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "\n",
    "                # Create target variable criterion.\n",
    "                ncc_clean_data[\"Funding Agency\"]  = ncc_clean_data[\"Fund\"].apply(lambda col_val: 'GOJ Funding' if col_val == 'GOJ' else 'Non-GOJ Funding')\n",
    "                ncc_clean_data[\"Funding Agency\"].head()\n",
    "\n",
    "                # -------------------------------------------------#\n",
    "                # Save clean dataset results to a file for future access.\n",
    "                # -------------------------------------------------#\n",
    "                ncc_clean_data.to_csv('ncc_consolidated_clean_file.csv', encoding='utf-8')\n",
    "\n",
    "\n",
    "                # To get whole EDA (Exploratory Data Analysis) using pandas_profiling.\n",
    "                #ProfileReport(ncc_clean_data)\n",
    "\n",
    "                ncc_data_df = ncc_clean_data.copy()\n",
    "\n",
    "                # Make copy of the sanitized data to build model.\n",
    "                data_sample = ncc_clean_data.copy()\n",
    "                dataset = ncc_clean_data.copy()\n",
    "\n",
    "\n",
    "                # The ncc_data_sample is categorial so I convert it with LabelEncoder to transfer to ordinal.\n",
    "                ncc_data_encoded = create_label_encoder_dict(ncc_clean_data)\n",
    "                print('\\n\\n')\n",
    "\n",
    "\n",
    "                # Used to convert categorical data, or text data, into numbers, which our predictive models can better understand.\n",
    "                print_label_endoder(ncc_data_encoded)\n",
    "                \n",
    "\n",
    "                # Transform dataset with encoding.\n",
    "                ncc_model = trans_data(data_sample, ncc_data_encoded)\n",
    "                    \n",
    "                # Make a copy of encoded data for Nearal Network model.\n",
    "                model_data = ncc_model.copy()\n",
    "                \n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # Give summary of the most frequent occurrence in the dataset.\n",
    "                print('\\t[-------- SUMMARY OF DATASET FREQUENCY --------]')\n",
    "                top = display_all(ncc_clean_data.describe(include='all').T)\n",
    "                print('\\n')\n",
    "\n",
    "                # Coontacts awarded on UTech behalf.\n",
    "                filter_data = ncc_clean_data[[\"Date\", \"Government Agency\", \"Jamaican Equivalent\", 'Funding Agency']]\n",
    "                filter = filter_data[\"Government Agency\"] == \"University of Technology, Jamaica\"\n",
    "\n",
    "                # Print only filter columns\n",
    "                # filter_data.where(filter).dropna()\n",
    "\n",
    "                #................................................. Visualizations ......................................#\n",
    "                # Contacts awarded on UWI behalf.\n",
    "                filter_df = ncc_clean_data[[\"Date\", \"Government Agency\", \"Jamaican Equivalent\", 'Funding Agency', 'Procurement Method']]\n",
    "                filter = filter_df[\"Government Agency\"] == \"University of the West Indies\"\n",
    "\n",
    "                # Print only filter columns\n",
    "                # filter_data.where(filter).dropna()\n",
    "\n",
    "                avg = filter_data['Jamaican Equivalent'].mean() \n",
    "                # print('\\n\\n')\n",
    "                \n",
    "                # View above average contract costs awarded in 2013.\n",
    "                above_avg_contracts = filter_data[(filter_data['Jamaican Equivalent'] > avg)] \n",
    "                # print(\"View above average contract costs awarded in 2013\",above_avg_contracts)\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "            \n",
    "                # Compare UTECH VS UWI Funding.\n",
    "                school = []\n",
    "                for name in filter_data[\"Government Agency\"]:\n",
    "                    if name == \"University of the West Indies\":\n",
    "                        school.append(\"UWI\")\n",
    "                    elif name == \"University of Technology, Jamaica\" or name == \"University of Technology, Jamaica (UTECH)\":\n",
    "                        school.append(\"UTECH\")\n",
    "                    else:\n",
    "                        school.append(\"Non-University\")\n",
    "\n",
    "                filter_data[\"University\"] = school\n",
    "                filter_data\n",
    "                \n",
    "                \n",
    "                # .................................................................................................................. #\n",
    "                # .................................................................................................................. #\n",
    "                print(\"\\t\\t\\t\\t---------- DATA VISUALIZATIONS ------------\")\n",
    "                print(\"\\n\\t\\t\\t\\t=========================================\")\n",
    "                \n",
    "                # You can set bins with nbinsx and nbinsy\n",
    "                # Multiple plots\n",
    "                #px.violin(ncc_clean_data, y=\"Procurement Method\", x=\"Jamaican Equivalent\", color=\"Fund\", box=True, points=\"all\",\n",
    "                          #hover_data=ncc_clean_data.columns)\n",
    "                    \n",
    "                # Now .groupby method is used to aggregate Jamaican Equivalent by date as well as sum Jamaican Equivalent per day.\n",
    "                cost_by_date = ncc_clean_data.groupby('Date')['Jamaican Equivalent'].sum()\n",
    "                cost_by_date.iplot(kind='scatter', title='Jamaican Equivalent JMD($) per Month')\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "\n",
    "                \n",
    "                # Distribution of University Funding Compare to Non-University Funding\n",
    "                school_funding = filter_data[\"University\"].value_counts()\n",
    "                school_funding.iplot(kind='bar', xTitle='University vs Non-University Funding',\n",
    "                                  yTitle='Frequency', title='University Funding Compares to Non-University Funding')\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # plotting the figure\n",
    "                fig = px.scatter_3d(ncc_clean_data, x=\"Procurement Method\", y=\"Funding Agency\", z=\"Jamaican Equivalent\", color='Fund',\n",
    "                                   title='3D Correlation between Jamaican Equivalent JMD($), Procurement Method & Funding Agency')\n",
    "\n",
    "                fig.show()\n",
    "                \n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                \n",
    "                # Graph showing the 10 most costly contracts that were awarded. \n",
    "                ncc_clean_data.iplot(kind=\"line\", theme=\"white\", x=\"Date\", y=\"Jamaican Equivalent\", xTitle='Year', \n",
    "                                     yTitle='Jamaican Equivalent', categories=\"Funding Agency\", title='Jamaican Equivalent JMD($) per Day Group by Agency')\n",
    "                \n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # Contracts Awarded per Quarter.\n",
    "                ncc_clean_data[\"Date\"].iplot(kind='hist', xTitle='Date',\n",
    "                                  yTitle='No. of Contracts', title='No. of Contracts Awarded per Quarter')\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "\n",
    "                # Procurement Method used for tendering for the contracts\n",
    "                ncc_clean_data[\"Procurement Method\"].iplot(kind='hist', xTitle='Procurement Method',\n",
    "                                  yTitle='No. of Contracts', title='Procurement Method Distribution for Contracts')\n",
    "                print('\\n\\n')\n",
    "\n",
    "                proc_count = ncc_clean_data[\"Procurement Method\"].value_counts()\n",
    "                \n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \n",
    "                \"\"\"\n",
    "                plt.figure(figsize=(16,8))\n",
    "                sns.set(style=\"darkgrid\")\n",
    "                sns.barplot(proc_count.index, proc_count.values, alpha=0.5)\n",
    "                plt.title(\"Frequency Distibution of Procurement Method\\n\")\n",
    "                plt.xlabel(\"Procurement Method\", fontsize=12)\n",
    "                plt.ylabel(\"Number of Occurrences\", fontsize=12)\n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "                \"\"\"\n",
    "\n",
    "                ncc_clean_data[\"Fund\"].iplot(kind='hist', xTitle='Fund',\n",
    "                                  yTitle='Contracts', title='No. of Contracts Funded by Agency')\n",
    "\n",
    "                jmd = ncc_data_sample['Jamaican Equivalent'].astype('float')\n",
    "                jmd.plot.hist(subplots=False, layout=(2,2), figsize=(16,14))\n",
    "\n",
    "                # Top (5) cost figures awarded Government contract values.\n",
    "                fig_jmd = pd.value_counts(jmd.values, sort=True).nlargest(5).plot(kind=\"bar\",figsize=(12,7))\n",
    "                plt.ylabel(\"Frequency\")\n",
    "                plt.xlabel(\"Jamaican Equivalent JMD($)\")\n",
    "                plt.title(\"\\nTop (5) Highest for Awarded Government Contracts\\n\") \n",
    "                \n",
    "                input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                clear_output()\n",
    "\n",
    "\n",
    "                print(\"\\n--------- DATA VISUALIZATION CONTINUES ----------\")\n",
    "                print(\"-------------------------------------------------\")\n",
    "\n",
    "                g_agency = ncc_clean_data[\"Government Agency\"].str.strip()\n",
    "\n",
    "                fig1 = pd.value_counts(g_agency.values, sort=True).nlargest(10).plot(kind=\"bar\",figsize=(12,8))\n",
    "                plt.ylabel(\"Contracts\")\n",
    "                plt.xlabel(\"Government Agency Contract Awarded\")\n",
    "                plt.title(\"\\nTen (10) Most Awarded Government Agency\\n\") \n",
    "                print('\\n\\n')\n",
    "\n",
    "                # Top eight (8) most used contractors for Goverment contract.\n",
    "                contractor = pd.value_counts(ncc_clean_data[\"Contractor\"].values, sort=True).nlargest(8)\n",
    "\n",
    "                labels = contractor.index\n",
    "                values = contractor\n",
    "\n",
    "                # pull is given as a fraction of the pie radius\n",
    "                fig = go.Figure(data=[go.Pie(title_text=\"Eight (8) Most used Contractors\\n\",\n",
    "                                             labels=labels, values=values, pull=[0.25, 0.25, 0.2, 0.15, 0.15, 0.1, 0.0, 0.0])])\n",
    "                fig.show()\n",
    "                print('\\n\\n')\n",
    "\n",
    "                # Six (6) Means Cost and Gov Agency.\n",
    "                group_data = ncc_clean_data \n",
    "                group_data[\"Cost\"] = jmd\n",
    "                group_data.groupby('Government Agency').Cost.mean().sort_values(ascending=True)[:6].plot.bar()\n",
    "                plt.ylabel(\"JMD ($)\")\n",
    "                plt.title(\"\\n\\nSix (6) Means Cost & Gov Agency\\n\") \n",
    "                print('\\n\\n')\n",
    "\n",
    "                # Six (6) Means Contract Cost & Funding Agency.\n",
    "                group_data = ncc_clean_data \n",
    "                group_data[\"Cost\"] = jmd\n",
    "                group_data.groupby('Fund').Cost.mean().sort_values(ascending=True)[:6].plot.bar()\n",
    "                plt.ylabel(\"JMD ($)\")\n",
    "                plt.title(\"\\n\\nEight (8) Means Contract Cost & Funding Agency\\n\") \n",
    "\n",
    "                # Ten (10) Miminum Contract Cost & Procurement Method used.\n",
    "                group_data = ncc_clean_data \n",
    "                group_data[\"Cost\"] = jmd\n",
    "                group_data.groupby('Procurement Method').Cost.min().sort_values(ascending=True)[:10].plot.bar()\n",
    "                plt.ylabel(\"JMD ($)\")\n",
    "                plt.title(\"\\n\\nTen Minimum  Contract Cost & Procurement Method used\\n\") \n",
    "\n",
    "                # Fifteen (15) Maximum Contract Cost & Dates Awarded.\n",
    "                group_data = ncc_clean_data \n",
    "                group_data[\"Cost\"] = jmd\n",
    "                group_data.groupby('Date').Cost.max().sort_values(ascending=True)[:15].plot.bar()\n",
    "                plt.ylabel(\"JMD ($)\")\n",
    "                plt.title(\"\\n\\nFifteen (15) Maximum Contract Cost & Dates Awarded\") \n",
    "                input(\"\\n\\t\\tPress Enter to return to main menu...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # Visualization to identify features that have a linear relationship with each other.\n",
    "                ncc_clean_data .pivot(columns='Procurement Method', values='Jamaican Equivalent').iplot(\n",
    "                kind='box',\n",
    "                yTitle='Jamaican Equivalent',\n",
    "                title='Procurement Method used Jamaican Equivalent JMD($) Contract Cost')\n",
    "                \n",
    "                input(\"\\n\\t\\tPress Enter to return to main menu...\")\n",
    "                clear_output()\n",
    "                \n",
    "                # -------------------------- Data Building ------------------------------------------------------------------ #\n",
    "                # ----------------------------------------------------------------------------------------------------------- #\n",
    "                inner_loop=True  \n",
    "                # Ensure data model is before data visualization.\n",
    "                flag = False\n",
    "        \n",
    "                while inner_loop:\n",
    "                    sub_menu()\n",
    "                    print('\\n\\n')\n",
    "                   \n",
    "                    # Accept user input for option here.\n",
    "                    opt = str(input(\"\\t\\tEnter your choice [0 - 3]: \"))\n",
    "                    #................................................................................................................#\n",
    "                    if opt=='0':  \n",
    "                        clear_output()\n",
    "                        print(\"\\n\\t\\tReturning to main menu...\")\n",
    "                    \n",
    "                        time.sleep(2)\n",
    "                        clear_output()\n",
    "                        inner_loop=False # This will make the while loop to end as not value of loop is set to False\n",
    "                    #..........................................................................................................# \n",
    "                    #................................................................................................................#\n",
    "                    elif opt=='1': \n",
    "                        \n",
    "                        clear_output()\n",
    "                        print(\"\\n\\t\\tDECISION TREE CLASSIFICATION\")\n",
    "                        print(\"\\t\\t----------------\\n\")\n",
    "                        \n",
    "                        # Building model phase. \n",
    "                        # Splitting dataset into test and train data.\n",
    "                        X_data, Y_data, X_train, X_test, y_train, y_test = splitdataset(ncc_model) \n",
    "\n",
    "                        \n",
    "                        # Show Y and X data axises.\n",
    "                        print_axis(X_data, Y_data)\n",
    "                        print(\"\\n\")\n",
    "                        \n",
    "                        # Validates percetage split.\n",
    "                        percentage_spit(X_train)\n",
    "                        \n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        # Create the classifier with a maximum depth of 2 using entropy as the criterion for choosing most \n",
    "                        #significant nodes to build the tree.\n",
    "                        # Ensure the model is not overfitted \"min_samples_split\"\n",
    "                        clf_entropy = tarin_using_entropy(X_train, y_train)\n",
    "                        \n",
    "                        clf_gini = train_using_gini(X_train, y_train)\n",
    "    \n",
    "                        print(\"\\n SIGNIFIGCANT RESULTS USING ENTROPY\") \n",
    "                        sig_features(clf_entropy, X_data)\n",
    "                        print(\"\\n\")\n",
    "                        \n",
    "                        print(\"\\n SIGNIFIGCANT RESULTS USING GINI\") \n",
    "                        sig_features(clf_gini, X_data)\n",
    "                        print(\"\\n\")\n",
    "                        \n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        \n",
    "                        print(\"\\nRESULTS USING ENTROPY\") \n",
    "                        print(\"-----------------------\") \n",
    "                        print(\"-----------------------\\n\") \n",
    "                        # Prediction using entropy. \n",
    "                        # Determine how many were predicted correctly.\n",
    "                        y_pred_entropy = prediction(X_test, clf_entropy, y_test)  \n",
    "                        cal_accuracy(y_test, y_pred_entropy) \n",
    "                        \n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        print(\"\\nRESULTS USING GINI\")\n",
    "                        print(\"------------------\") \n",
    "                        print(\"------------------\\n\") \n",
    "                        # Prediction using gini. \n",
    "                        # Determine how many were predicted correctly.\n",
    "                        y_pred_gini = prediction(X_test, clf_gini, y_test)\n",
    "                        cal_accuracy(y_test, y_pred_gini) \n",
    "                        \n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        # Visualize Decision tree using entropy.\n",
    "                        entropy_graph = tree_visualization(ncc_data_encoded, clf_entropy, X_data, Y_data)  \n",
    "                        graphviz.Source(entropy_graph) \n",
    "                        \n",
    "                        # The Confusion matrix compares the actual target values with those predicted by the machine learning model.\n",
    "                        entropy_cm = confusion_matrix(y_test, clf_entropy.predict(X_test), labels=y_test.unique())\n",
    "                        entropy_cm\n",
    "                        \n",
    "                        plt.figure(figsize=(25,20))\n",
    "                        plot_confusion_matrix(entropy_cm, ncc_clean_data['Funding Agency'].unique())\n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        #Print text representation of Plot Tree with plot_tree.\n",
    "                        print (\"\\n\\n\\t\\t[---  Print text representation of Plot Tree with plot_tree ---]\\n\\n\")\n",
    "                        text_representation = tree.export_text(clf_entropy)\n",
    "                        print(text_representation)\n",
    "                        print(\"\\n\\n\")\n",
    "                        \n",
    "                        # Visualize Decision using Plot Tree with plot_tree.\n",
    "                        fig = plt.figure(figsize=(25,20))\n",
    "                        _ = tree.plot_tree(clf_entropy,\n",
    "                            feature_names=X_data.columns, \n",
    "                            class_names=ncc_data_encoded[Y_data.name].classes_,  \n",
    "                            filled=True, rounded=True,  proportion=True,\n",
    "                            node_ids=True)\n",
    "                        \n",
    "                        # Used save the figure to the .png file.\n",
    "                        fig.savefig(\"decistion_tree.png\")\n",
    "                        \n",
    "                        # Visualize Decision tree using gini.\n",
    "                        gini_graph = tree_visualization(ncc_data_encoded, clf_gini, X_data, Y_data)  \n",
    "                        graphviz.Source(gini_graph)\n",
    "                        \n",
    "                        gini_cm = confusion_matrix(y_test, clf_gini.predict(X_test), labels=y_test.unique())\n",
    "                        pd.DataFrame(gini_cm)  \n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        # The matrix compares the actual target values with those predicted by the machine learning model.\n",
    "                        plt.figure(figsize=(8,8))\n",
    "                        plot_confusion_matrix(gini_cm, ncc_clean_data['Funding Agency'].unique())\n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "                        \n",
    "                        # Validates data model has been built for visualization.\n",
    "                        flag = True\n",
    "                        \n",
    "                    #..........................................................................................................#\n",
    "                    #................................................................................................................#\n",
    "                    elif opt=='2': \n",
    "                        clear_output()   \n",
    "                        \n",
    "                        print(\"\\n\\t\\tBUILD NEURAL NETWORK CLASSIFICATION MODEL\")\n",
    "                        print(\"\\n\\t\\t=========================================\")\n",
    "                        print(\"\\n\")\n",
    "\n",
    "                        dataset= ncc_data_df.copy()\n",
    "                        encoded_model = model_data.copy()\n",
    "\n",
    "                        # Building model phase. \n",
    "                        # Splitting dataset into test and train data.\n",
    "                        X_features, Y_target, X_train_1, X_test_1, y_train_1, y_test_1 = splitdataset(encoded_model) \n",
    "\n",
    "\n",
    "                        # Show Y and X data axises.\n",
    "                        print_axis(X_features, Y_target)\n",
    "                        print(\"\\n\")\n",
    "\n",
    "\n",
    "                        # Validates percetage split.\n",
    "                        print(\"Validates percetage split : \\n\")\n",
    "                        percentage_spit(X_train_1)\n",
    "\n",
    "                        print(\"\\n\\n\")\n",
    "\n",
    "                        # Create an instance of linear regression.\n",
    "                        reg = MLPClassifier()\n",
    "\n",
    "\n",
    "                        # Fits a linear model\n",
    "                        reg.fit(X_train_1, y_train_1)\n",
    "\n",
    "\n",
    "                        # Number of layers utilized by the model.\n",
    "                        print(\"Number of layers in model : \", reg.n_layers_)\n",
    "\n",
    "\n",
    "                        # Predicting the Test set results\n",
    "                        test_predicted = reg.predict(X_test_1)\n",
    "                        test_predicted\n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "\n",
    "\n",
    "                        # Determine how many were predicted correctly.\n",
    "                        print(\"Determine how many were predicted correctly :\")\n",
    "                        k = (reg.predict(X_test_1) == y_test_1) \n",
    "                        pd.DataFrame(k.value_counts())\n",
    "                        \n",
    "\n",
    "                        # Count how many were predicted correctly.\n",
    "                        k.value_counts().iplot(kind='bar', xTitle='Prediction',\n",
    "                                          yTitle='Count', title='Funding Agency Prediction Distribution')\n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "\n",
    "\n",
    "                        # with one slide exploded out\n",
    "                        explode=(0.1, 0.0)\n",
    "                        colors = ['gold', 'red']\n",
    "\n",
    "                        k_count = k.value_counts()\n",
    "                        k_df = pd.DataFrame({'labels': k_count.index, 'values': k_count.values})\n",
    "\n",
    "                        k_df.iplot(kind='pie',labels='labels',values='values', colors=colors, title='Neural Network Funding Agency Prediction', hole = 0.5) \n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "\n",
    "                        cm_network=confusion_matrix(y_test_1, reg.predict(X_test_1), labels=y_test_1.unique())\n",
    "                        cm_network\n",
    "\n",
    "                        # Confusion Matrix for Funding Agency. \n",
    "                        plt.figure(figsize=(6,6))\n",
    "                        plot_confusion_matrix(cm_network, dataset['Funding Agency'].unique())\n",
    "                        input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                        clear_output()\n",
    "\n",
    "\n",
    "                        #Evaluation for Neural Network Classification. \n",
    "                        cal_accuracy(y_test_1, test_predicted) \n",
    "                        print('\\n\\n')\n",
    "\n",
    "\n",
    "                        network_accuracy = round((accuracy_score(y_test_1, test_predicted)*100), 1)\n",
    "                        \n",
    "                        # Validates data has been processed for visualization.\n",
    "                        if flag == False:\n",
    "                            print (\"\\n\\t\\t[....  PLEASE BUILD DECISION TREE TO INITIALIZE Y_TEST  ....]\")\n",
    "                            time.sleep(3)\n",
    "                            clear_output()\n",
    "                        elif flag == True:\n",
    "                \n",
    "                            entropy_accuracy = round((accuracy_score(y_test, y_pred_entropy)*100), 1)\n",
    "                            gini_accuracy = round((accuracy_score(y_test, y_pred_gini)*100), 1)\n",
    "\n",
    "                            entropy_accuracy\n",
    "                            gini_accuracy\n",
    "                            network_accuracy\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "\n",
    "                            #Result for prediction accuracy of the model.\n",
    "                            accuracy_results = pd.DataFrame({'Entropy_accuracy':[entropy_accuracy], \n",
    "                                                             'Gini_accuracy':[gini_accuracy], 'Network_accuracy':[network_accuracy]}) \n",
    "\n",
    "                            accuracy_results.iplot(kind='bar', xTitle='[Entrop] \\t\\t\\t\\t\\t\\t [Gini] \\t\\t\\t\\t [Nueral Network]',\n",
    "                                                   yTitle='Percentage (%)', title='Entrop, Gini & Network Prediction Accuracy Score')\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "                        \n",
    "                    #..........................................................................................................#  \n",
    "                    #..........................................................................................................#  \n",
    "                    elif opt=='3': \n",
    "                        # Validates data has been processed for visualization.\n",
    "                        if flag == False:\n",
    "                            print (\"\\n\\t\\t[....  PLEASE BUILD DECISION TREE MODELS BEFORE VISUALIZTAIONS  ....]\")\n",
    "                            time.sleep(2)\n",
    "                            clear_output()\n",
    "                        elif flag == True:\n",
    "                            clear_output()\n",
    "                            print(\"\\n\\t\\tDATASET VISUALIZATIONS \")\n",
    "                            print(\"\\n\\t\\t-----------------------\")\n",
    "                            \n",
    "                            ncc_clean_data.iplot(kind=\"scatter\", theme=\"white\", x=\"Procurement Method\", y=\"Jamaican Equivalent\",\n",
    "                            xTitle='Procurement Method', yTitle='Jamaican Equivalent', categories=\"Funding Agency\")\n",
    "                            \n",
    "                            \n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "                            # Visualization to identify a correlation between Government Agency and Funding Agency.\n",
    "                            #sns.histplot(ncc_clean_data['Fund'], ncc_clean_data['Government Agency'])\n",
    "                            #sns.jointplot(ncc_clean_data['Fund'], ncc_clean_data['Government Agency'])\n",
    "\n",
    "                            ncc_clean_data.pivot(columns='Jamaican Equivalent', values='Government Agency').iplot(\n",
    "                            kind='box',\n",
    "                            yTitle='Government Agency',\n",
    "                            title='Jamaican Equivalent Distribution by Government Agency')\n",
    "\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "                            # Visualization to identify a correlation between Government Agency and Funding Agency.\n",
    "                            contractor_gov = JointPlotVisualizer(feature='Contractor', target='Government Agency')\n",
    "                            contractor_gov.fit(X_data['Contractor'], X_data['Government Agency'])\n",
    "                            contractor_gov.fig.suptitle('Correlation between Contractor and Government Agency') \n",
    "                            contractor_gov.poof()\n",
    "\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "                            # Graph showing cost distribution of awarded c\\ontracts. \n",
    "                            plt.hist(ncc_clean_data[\"Jamaican Equivalent\"])\n",
    "                            plt.title('Cost Distribution of Awarded Contracts')\n",
    "                            plt.xlabel('JMD ($)')\n",
    "                            plt.ylabel('Number');\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "\n",
    "                            # Find the most common Procurement Method used by the Goverment Agencies.\n",
    "                            p_method = ncc_model['Procurement Method']\n",
    "                            p_method_values = ncc_clean_data['Procurement Method']\n",
    "\n",
    "                            print(\"MOST FREQUENT Procurement Method used : \", stats.mode(p_method))\n",
    "                            print(\"\\n\\n\")\n",
    "                            print(\"MOST FREQUENT Procurement Method used : \", stats.mode(p_method_values))\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "                            # Graph showing the 10 most costly contracts that were awarded. \n",
    "                            contract_cost = ncc_model[['Date', 'Government Agency', 'Contractor', 'Jamaican Equivalent']]\n",
    "                            contract_cost.nlargest(10, \"Jamaican Equivalent\").plot(kind=\"line\", \n",
    "                            x='Contractor', y='Jamaican Equivalent', title=\"TEN MOST COSTLY CONTRACTS AWARDED\", figsize=(10,8))\n",
    "                            plt.title(\"Dates from %d to %d\" % (contract_cost['Date'].min(), contract_cost['Date'].max()),size=8)\n",
    "                            plt.suptitle(\"Contractor per Cost\",size=12)\n",
    "                            plt.ylabel(\"Jamaican Equivalent\")\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "                            # Data for customizinig pie chart.\n",
    "                            sizes = [225, 130, 245, 210]\n",
    "                            explode = (0.1, 0, 0.1, 0, 0.1,0.1, 0, 0.1, 0, 0.1)  # explode 1st slice\n",
    "\n",
    "                            # Graph showing the 10 most costly contracts that were awarded. \n",
    "                            contract_cost = ncc_model[['Date', 'Government Agency', 'Contractor', 'Jamaican Equivalent']]\n",
    "                            contract_cost.nlargest(10, \"Jamaican Equivalent\").plot.pie(autopct='%2.1f%%', explode=explode,\n",
    "                            x='Contractor', y='Jamaican Equivalent', title=\"TEN MOST COSTLY CONTRACTS AWARDED\", figsize=(10,8))\n",
    "                            plt.title(\"Dates from %d to %d\" % (contract_cost['Date'].min(), contract_cost['Date'].max()),size=8)\n",
    "                            plt.suptitle(\"Ten(10) Most Costly Contractors per Cost\",size=12)\n",
    "                            plt.ylabel(\"Jamaican Equivalent\")\n",
    "\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "\n",
    "                            # Graph showing the 10 most costly contracts that were awarded group by Procurement Method.\n",
    "                            gov_agency = ncc_data.nlargest(10, \"Jamaican Equivalent\")\n",
    "                            print(gov_agency.boxplot(column='Jamaican Equivalent', by = 'Procurement Method', figsize=(10,8)))\n",
    "\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "\n",
    "                            # Visualization to identify features that have a linear relationship with each other.\n",
    "                            #correlation = Rank2D(algorithm=\"pearson\")\n",
    "                            #correlation.fit_transform(X_data)\n",
    "                            #correlation.poof()\n",
    "\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "\n",
    "                            # Visualization to identify a correlation between Government Agency and Funding Agency.\n",
    "                            contractor_gov = JointPlotVisualizer(feature='Fund', target='Government Agency')\n",
    "                            contractor_gov.fit(X_data['Fund'], X_data['Government Agency'])\n",
    "                            contractor_gov.fig.suptitle('Correlation between Contractor and Government Agency') \n",
    "                            contractor_gov.poof()\n",
    "\n",
    "                            input(\"\\n\\t\\tPress Enter to continue...\")\n",
    "                            clear_output()\n",
    "                                                     \n",
    "                    #..........................................................................................................#               \n",
    "                    #..........................................................................................................#\n",
    "                    else:\n",
    "                        # Any integer inputs other than values 0 - 2 we print an error message\n",
    "                        print(\"\\n\\t\\t\\tWrong option selection! Please try again...\")\n",
    "                        time.sleep(2)\n",
    "                        clear_output()\n",
    "            #..........................................................................................................#\n",
    "            #..........................................................................................................#   \n",
    "            else:\n",
    "                # Any integer inputs other th1an values 0 & 1 we print an error message\n",
    "                print(\"\\t\\t\\tWrong option selection! Please try again...\")\n",
    "                time.sleep(2)\n",
    "                clear_output()\n",
    "    #----------------------------------------------------------------------------------------------------------------#          \n",
    "    except IOError:\n",
    "        print (\"*ERROR LOADING APPLICATION!\")  \n",
    "        clear_output()\n",
    "    #----------------------------------------------------------------------------------------------------------------#          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\t\t~~                                                        ~~\n",
      "\n",
      "\t\t~~      DATA WAREHOUSE & DATA MINING VISUALIZATION        ~~\n",
      "\n",
      "\t\t~~               (BUILD DATA MODEL)                       ~~\n",
      "\n",
      "\t\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\t\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\t\t~~                                                        ~~\n",
      "\n",
      "\t\t~~          ->0. RETURN TO MAIN                           ~~\n",
      "\n",
      "\t\t~~          ->1. DECISION TREE CLASSIFICATION             ~~\n",
      "\n",
      "\t\t~~          ->2. NEURAL NETWORK CLASSIFICATION            ~~\n",
      "\n",
      "\t\t~~          ->3. DATASET VISUALIZATIONS                   ~~\n",
      "\n",
      "\t\t~~                                                        ~~\n",
      "\n",
      "\t\t~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## # \n",
    "## \n",
    "### # ## ## Driver code for main program.\n",
    "def main(): \n",
    "        app_menu()\n",
    "\n",
    "## Calling main function. \n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    main()\n",
    "## Codes end here.\n",
    "#----------------------------------------------------------------------------------------------------------------#          \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
